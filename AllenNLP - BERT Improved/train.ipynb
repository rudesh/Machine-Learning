{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bzdKNWpr1Lue","colab_type":"code","colab":{}},"source":["pip install allennlp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hj_eEwGYzhxQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"490ddb28-2b56-403f-d6c5-3286b78ccdc4","executionInfo":{"status":"ok","timestamp":1557432664268,"user_tz":-180,"elapsed":1003,"user":{"displayName":"Rudaya Sekaran","photoUrl":"https://lh6.googleusercontent.com/-dRrHqiFSo6I/AAAAAAAAAAI/AAAAAAAAATs/gEE_q1qiqzk/s64/photo.jpg","userId":"16410537103600396272"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/My Drive/Colab Notebooks/NLP Labs/hw 6"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/Colab Notebooks/NLP Labs/hw 6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pz8PX6kwztvv","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.insert(0, '/content/gdrive/My Drive/Colab Notebooks/NLP Labs/hw 6')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nu9HYsXWz0BI","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import StanfordSentimentTreeBankDatasetReader\n","from allennlp.data.iterators import BucketIterator\n","from allennlp.data.token_indexers import PretrainedBertIndexer\n","from allennlp.data.vocabulary import Vocabulary\n","from allennlp.models import archive_model\n","from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n","from allennlp.modules.token_embedders import PretrainedBertEmbedder\n","from allennlp.training.trainer import Trainer\n","\n","from sst_classifier import LstmClassifier\n","from transformer_encoder import TransformerSeq2VecEncoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGLgb1kQ1J-m","colab_type":"code","colab":{}},"source":["HIDDEN = 256\n","EMBEDDED = 512\n","max_sequence_length = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMdkXihPDi5M","colab_type":"code","colab":{}},"source":["token_indexer = PretrainedBertIndexer(pretrained_model='bert-base-uncased', max_pieces=max_sequence_length, do_lowercase=True)\n","\n","reader = StanfordSentimentTreeBankDatasetReader(token_indexers={'tokens': token_indexer})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHs-J8OJIMjI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"790c2158-fa41-4d06-da65-d2c0152c5e8c","executionInfo":{"status":"ok","timestamp":1557432668559,"user_tz":-180,"elapsed":5260,"user":{"displayName":"Rudaya Sekaran","photoUrl":"https://lh6.googleusercontent.com/-dRrHqiFSo6I/AAAAAAAAAAI/AAAAAAAAATs/gEE_q1qiqzk/s64/photo.jpg","userId":"16410537103600396272"}}},"source":["train_dataset = reader.read('trees/train.txt')\n","dev_dataset = reader.read('trees/dev.txt')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["8544it [00:02, 4127.07it/s]\n","1101it [00:00, 5304.12it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QJL7D5U8IOfg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"084cb955-d1b3-465f-c373-e757083dd657","executionInfo":{"status":"ok","timestamp":1557432668866,"user_tz":-180,"elapsed":5558,"user":{"displayName":"Rudaya Sekaran","photoUrl":"https://lh6.googleusercontent.com/-dRrHqiFSo6I/AAAAAAAAAAI/AAAAAAAAATs/gEE_q1qiqzk/s64/photo.jpg","userId":"16410537103600396272"}}},"source":["vocab = Vocabulary.from_instances(train_dataset + dev_dataset, min_count={'tokens': 3})"],"execution_count":8,"outputs":[{"output_type":"stream","text":["100%|██████████| 9645/9645 [00:00<00:00, 143105.49it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gc7ywe9LIWio","colab_type":"code","colab":{}},"source":["bert_embedder = PretrainedBertEmbedder(pretrained_model='bert-base-uncased', top_layer_only=True)\n","\n","word_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": bert_embedder}, allow_unmatched_keys=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmAzG3XeIYaI","colab_type":"code","colab":{}},"source":["encoder = TransformerSeq2VecEncoder(EMBEDDED, HIDDEN, projection_dim=128, feedforward_hidden_dim=128, num_layers=2, num_attention_heads=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEH6hP7ZIai2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":5814},"outputId":"48da17d2-77f4-4002-9ed3-69db56929938","executionInfo":{"status":"ok","timestamp":1557432680751,"user_tz":-180,"elapsed":17421,"user":{"displayName":"Rudaya Sekaran","photoUrl":"https://lh6.googleusercontent.com/-dRrHqiFSo6I/AAAAAAAAAAI/AAAAAAAAATs/gEE_q1qiqzk/s64/photo.jpg","userId":"16410537103600396272"}}},"source":["model_bert = LstmClassifier(word_embeddings, encoder, vocab)\n","model_bert.cuda()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LstmClassifier(\n","  (word_embeddings): BasicTextFieldEmbedder(\n","    (token_embedder_tokens): PretrainedBertEmbedder(\n","      (bert_model): BertModel(\n","        (embeddings): BertEmbeddings(\n","          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","          (position_embeddings): Embedding(512, 768)\n","          (token_type_embeddings): Embedding(2, 768)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1)\n","        )\n","        (encoder): BertEncoder(\n","          (layer): ModuleList(\n","            (0): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (1): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (2): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (3): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (4): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (5): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (6): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (7): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (8): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (9): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (10): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","            (11): BertLayer(\n","              (attention): BertAttention(\n","                (self): BertSelfAttention(\n","                  (query): Linear(in_features=768, out_features=768, bias=True)\n","                  (key): Linear(in_features=768, out_features=768, bias=True)\n","                  (value): Linear(in_features=768, out_features=768, bias=True)\n","                  (dropout): Dropout(p=0.1)\n","                )\n","                (output): BertSelfOutput(\n","                  (dense): Linear(in_features=768, out_features=768, bias=True)\n","                  (LayerNorm): BertLayerNorm()\n","                  (dropout): Dropout(p=0.1)\n","                )\n","              )\n","              (intermediate): BertIntermediate(\n","                (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              )\n","              (output): BertOutput(\n","                (dense): Linear(in_features=3072, out_features=768, bias=True)\n","                (LayerNorm): BertLayerNorm()\n","                (dropout): Dropout(p=0.1)\n","              )\n","            )\n","          )\n","        )\n","        (pooler): BertPooler(\n","          (dense): Linear(in_features=768, out_features=768, bias=True)\n","          (activation): Tanh()\n","        )\n","      )\n","    )\n","  )\n","  (linear_bn): Linear(in_features=768, out_features=512, bias=True)\n","  (encoder): TransformerSeq2VecEncoder(\n","    (seq_2_seq): StackedSelfAttentionEncoder(\n","      (feedforward_0): FeedForward(\n","        (_linear_layers): ModuleList(\n","          (0): Linear(in_features=512, out_features=128, bias=True)\n","          (1): Linear(in_features=128, out_features=256, bias=True)\n","        )\n","        (_dropout): ModuleList(\n","          (0): Dropout(p=0.1)\n","          (1): Dropout(p=0.1)\n","        )\n","      )\n","      (feedforward_layer_norm_0): LayerNorm()\n","      (self_attention_0): MultiHeadSelfAttention(\n","        (_combined_projection): Linear(in_features=256, out_features=384, bias=True)\n","        (_output_projection): Linear(in_features=128, out_features=256, bias=True)\n","        (_attention_dropout): Dropout(p=0.1)\n","      )\n","      (layer_norm_0): LayerNorm()\n","      (feedforward_1): FeedForward(\n","        (_linear_layers): ModuleList(\n","          (0): Linear(in_features=256, out_features=128, bias=True)\n","          (1): Linear(in_features=128, out_features=256, bias=True)\n","        )\n","        (_dropout): ModuleList(\n","          (0): Dropout(p=0.1)\n","          (1): Dropout(p=0.1)\n","        )\n","      )\n","      (feedforward_layer_norm_1): LayerNorm()\n","      (self_attention_1): MultiHeadSelfAttention(\n","        (_combined_projection): Linear(in_features=256, out_features=384, bias=True)\n","        (_output_projection): Linear(in_features=128, out_features=256, bias=True)\n","        (_attention_dropout): Dropout(p=0.1)\n","      )\n","      (layer_norm_1): LayerNorm()\n","      (dropout): Dropout(p=0.2)\n","    )\n","  )\n","  (linear): Linear(in_features=256, out_features=5, bias=True)\n","  (loss_function): CrossEntropyLoss()\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"YkUWMEsxIcSy","colab_type":"code","colab":{}},"source":["optimizer = optim.Adam(model_bert.parameters(), lr=1e-4, weight_decay=1e-5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9VZ6ITBIe_d","colab_type":"code","colab":{}},"source":["iterator = BucketIterator(batch_size=64, sorting_keys=[(\"tokens\", \"num_tokens\")])\n","\n","iterator.index_with(vocab)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbDT4GlqIguI","colab_type":"code","colab":{}},"source":["trainer = Trainer(model=model_bert, optimizer=optimizer, iterator=iterator, train_dataset=train_dataset, validation_dataset=dev_dataset, cuda_device=0, patience=5, num_epochs=20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONbEI-iyIjEu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"00a0aac9-007b-48e8-d4e2-7170410170ab","executionInfo":{"status":"ok","timestamp":1557432947941,"user_tz":-180,"elapsed":284578,"user":{"displayName":"Rudaya Sekaran","photoUrl":"https://lh6.googleusercontent.com/-dRrHqiFSo6I/AAAAAAAAAAI/AAAAAAAAATs/gEE_q1qiqzk/s64/photo.jpg","userId":"16410537103600396272"}}},"source":["history = trainer.train()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["accuracy: 0.2960, precision: 0.2437, recall: 0.0266, f1_measure: 0.0479, loss: 1.5637 ||: 100%|██████████| 134/134 [00:20<00:00,  6.09it/s]\n","accuracy: 0.3942, precision: 0.0000, recall: 0.0000, f1_measure: 0.0000, loss: 1.3816 ||: 100%|██████████| 18/18 [00:02<00:00,  6.90it/s]\n","accuracy: 0.4158, precision: 0.3731, recall: 0.1145, f1_measure: 0.1752, loss: 1.3124 ||: 100%|██████████| 134/134 [00:20<00:00,  5.52it/s]\n","accuracy: 0.4251, precision: 0.5385, recall: 0.0504, f1_measure: 0.0921, loss: 1.3084 ||: 100%|██████████| 18/18 [00:02<00:00,  6.99it/s]\n","accuracy: 0.4526, precision: 0.4064, recall: 0.2225, f1_measure: 0.2876, loss: 1.2345 ||: 100%|██████████| 134/134 [00:19<00:00,  6.74it/s]\n","accuracy: 0.4296, precision: 0.4118, recall: 0.2518, f1_measure: 0.3125, loss: 1.2711 ||: 100%|██████████| 18/18 [00:02<00:00,  7.30it/s]\n","accuracy: 0.4772, precision: 0.5016, recall: 0.2793, f1_measure: 0.3588, loss: 1.1877 ||: 100%|██████████| 134/134 [00:19<00:00,  6.95it/s]\n","accuracy: 0.4242, precision: 0.3393, recall: 0.5468, f1_measure: 0.4187, loss: 1.2552 ||: 100%|██████████| 18/18 [00:02<00:00,  7.39it/s]\n","accuracy: 0.4923, precision: 0.4915, recall: 0.3178, f1_measure: 0.3860, loss: 1.1647 ||: 100%|██████████| 134/134 [00:19<00:00,  6.97it/s]\n","accuracy: 0.4105, precision: 0.3598, recall: 0.4892, f1_measure: 0.4146, loss: 1.3215 ||: 100%|██████████| 18/18 [00:02<00:00,  7.42it/s]\n","accuracy: 0.5092, precision: 0.4845, recall: 0.3425, f1_measure: 0.4013, loss: 1.1383 ||: 100%|██████████| 134/134 [00:19<00:00,  5.39it/s]\n","accuracy: 0.4659, precision: 0.4219, recall: 0.3885, f1_measure: 0.4045, loss: 1.2347 ||: 100%|██████████| 18/18 [00:02<00:00,  7.19it/s]\n","accuracy: 0.5199, precision: 0.5397, recall: 0.3736, f1_measure: 0.4416, loss: 1.1152 ||: 100%|██████████| 134/134 [00:19<00:00,  5.35it/s]\n","accuracy: 0.4623, precision: 0.4304, recall: 0.2446, f1_measure: 0.3119, loss: 1.2276 ||: 100%|██████████| 18/18 [00:02<00:00,  7.26it/s]\n","accuracy: 0.5261, precision: 0.5388, recall: 0.4002, f1_measure: 0.4593, loss: 1.0921 ||: 100%|██████████| 134/134 [00:19<00:00,  6.08it/s]\n","accuracy: 0.4750, precision: 0.6279, recall: 0.1942, f1_measure: 0.2967, loss: 1.2647 ||: 100%|██████████| 18/18 [00:02<00:00,  7.34it/s]\n","accuracy: 0.5420, precision: 0.5310, recall: 0.4002, f1_measure: 0.4564, loss: 1.0766 ||: 100%|██████████| 134/134 [00:19<00:00,  6.80it/s]\n","accuracy: 0.4578, precision: 0.4179, recall: 0.4029, f1_measure: 0.4103, loss: 1.2335 ||: 100%|██████████| 18/18 [00:02<00:00,  7.32it/s]\n","accuracy: 0.5556, precision: 0.5603, recall: 0.4167, f1_measure: 0.4779, loss: 1.0429 ||: 100%|██████████| 134/134 [00:19<00:00,  6.32it/s]\n","accuracy: 0.4469, precision: 0.3947, recall: 0.4317, f1_measure: 0.4124, loss: 1.3265 ||: 100%|██████████| 18/18 [00:02<00:00,  7.21it/s]\n","accuracy: 0.5639, precision: 0.5659, recall: 0.4441, f1_measure: 0.4977, loss: 1.0255 ||: 100%|██████████| 134/134 [00:19<00:00,  7.27it/s]\n","accuracy: 0.4605, precision: 0.4321, recall: 0.2518, f1_measure: 0.3182, loss: 1.3217 ||: 100%|██████████| 18/18 [00:02<00:00,  7.28it/s]\n","accuracy: 0.5804, precision: 0.5693, recall: 0.4625, f1_measure: 0.5104, loss: 0.9998 ||: 100%|██████████| 134/134 [00:19<00:00,  8.97it/s]\n","accuracy: 0.4478, precision: 0.3964, recall: 0.4820, f1_measure: 0.4351, loss: 1.3275 ||: 100%|██████████| 18/18 [00:02<00:00,  7.31it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wcNY9C82IlGO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"c1eff060-0681-438e-bec1-d50c447ff8b3","executionInfo":{"status":"ok","timestamp":1557432947943,"user_tz":-180,"elapsed":284571,"user":{"displayName":"Rudaya Sekaran","photoUrl":"https://lh6.googleusercontent.com/-dRrHqiFSo6I/AAAAAAAAAAI/AAAAAAAAATs/gEE_q1qiqzk/s64/photo.jpg","userId":"16410537103600396272"}}},"source":["history"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'best_epoch': 6,\n"," 'best_validation_accuracy': 0.4623069936421435,\n"," 'best_validation_f1_measure': 0.31192660550454093,\n"," 'best_validation_loss': 1.22759124967787,\n"," 'best_validation_precision': 0.43037974683544306,\n"," 'best_validation_recall': 0.2446043165467626,\n"," 'epoch': 10,\n"," 'peak_cpu_memory_MB': 4218.396,\n"," 'peak_gpu_0_memory_MB': 2215,\n"," 'training_accuracy': 0.5639044943820225,\n"," 'training_cpu_memory_MB': 4218.396,\n"," 'training_duration': '00:04:05',\n"," 'training_epochs': 10,\n"," 'training_f1_measure': 0.4976911236531062,\n"," 'training_gpu_0_memory_MB': 2215,\n"," 'training_loss': 1.0254951897841782,\n"," 'training_precision': 0.5659276546091015,\n"," 'training_recall': 0.4441391941391941,\n"," 'training_start_epoch': 0,\n"," 'validation_accuracy': 0.4604904632152589,\n"," 'validation_f1_measure': 0.31818181818177166,\n"," 'validation_loss': 1.3216620087623596,\n"," 'validation_precision': 0.43209876543209874,\n"," 'validation_recall': 0.2517985611510791}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"h_JA18d3NtME","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}